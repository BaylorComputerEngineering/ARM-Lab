\chapter{Pipeline Fetch and Decode}


\section{Pipeline Fetch and Decode}
Now that we have a working single-cycle datapath, we are going to break it apart and start pipelining it.  Make sure to keep a copy of your working single cycle datapath for reference.  To begin the pipelining process, we will first pipeline the iFetch and iDecode stages.

The advantage of pipelining includes the ability to reduce the clock cycle time by doing only one stage at a time.  We have been using a 10ns clock cycle.  Now that we are pipelining, let's start conservative and go down to a 4ns clock cycle.  Please keep it at 4ns for now to maintain consistency across the class.  

This will affect your timing and will require you to update the clocks in your datapath.  The basic clk for each stage should be clk (no delays).  You will still need delayed clocks for items that are delayed within a stage such as read\_clk and write\_clk.  The first goal for your pipeline is to get a series of instructions to execute in pipeline form, where a new instruction is fetched while the previous instruction is being decoded.  You should verify this by examining the Read\_Register values, Read\_Data values, control signal values, etc.  To test this, use your set of instructions that corresponds to your Expected Results table.  You should not have to make a lot of updates, as the instr\_parse module was made partially for the purpose of buffering data, making pipelining easier.  For right now, just focus on the Fetch and Decode stages.

\section{Pipeline Buffering and Forwarding}
The next step in developing your pipeline is to add the stage buffers that we have seen in the textbook.  The idea here is that every input to a stage must be buffered.  The code for this is not complex, but the planning and thought process can be complex because some signals need to be passed through to future stages.  Remember, you should not have signals that go from Decode to Memory, for example.  If you do, the data will be incorrect due to timing issues.  To aid your efforts, I require that you complete the PipelineAnalysisTemplate.xlsx.  This allows you to figure out what signals need to be passed between stages and develops a naming convention that will help you when you start implementing. 

In the spreadsheet, you should start with my template, which has many (not all) of the signals that are in your datapath.  Look at your current connections in datapath.v.  Wherever you see an output from a module, put that in the spreadsheet as a source.  Wherever you see an input to a module, put that in the spreadsheet as a destination.  In many cases, you will see that there is space in the spreadsheet between the source and destination.  This means that the signal must be buffered and forwarded from one stage to the next.  Fill in the space between the source and destination with signals to be forwarded.  Please use the naming convention that I show on the spreadsheet....this might be the most crucial part.  The signal names should match your current signal names, but they should have a suffix added to them that indicates which stage outputted the data.  For instance, when mem\_to\_reg was buffered in iExecute and forwarded to iMemory, the signal should be name mem\_to\_reg\_ie because iExecute outputs the data. 


\section{Your Assignment}

You are to:
\begin{enumerate}
\item Save a copy of your non-pipelined datapath.v.
\item Comment out Execute, Memory, and WriteBack stages from datapath.v.
\item Pipeline iFetch and iDecode stages as described above.   
\item Test with your set of instructions from your Expected Results table.
\item Verify that stages are processing the correct instructions at the correct times.
\item Complete PipelineAnalysisTemplate.xlsx
\item There is no lab report today.
\end{enumerate} 